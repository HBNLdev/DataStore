{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add another box to specify extensions to delete??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/dbI/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import (QMainWindow, QApplication, QPushButton, QWidget, QAction, \n",
    "                             QTabWidget,QVBoxLayout, QHBoxLayout, QInputDialog, QLineEdit, QLabel,\n",
    "                             QFileDialog, QMainWindow, QPushButton)\n",
    "from PyQt5.QtGui import QIcon\n",
    "from PyQt5.QtCore import pyqtSlot, QCoreApplication\n",
    "\n",
    "    \n",
    "class App(QMainWindow):        \n",
    " \n",
    "    def __init__(self):   \n",
    "        super(App, self).__init__()\n",
    "        \n",
    "        self.title = 'Site Data Utilities'\n",
    "        self.left = 0\n",
    "        self.top = 0\n",
    "        self.width = 600\n",
    "        self.height = 400\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        \n",
    " \n",
    "        # Initialize tab widget\n",
    "        self.tabs = QTabWidget()\n",
    "        \n",
    "        # create tabs \n",
    "        self.h1Tab = QWidget()\n",
    "        self.neuroTab = QWidget()\n",
    "        \n",
    "        #################################### ERP TAB ####################################\n",
    "        \n",
    "        # create vertical layout for ERP tab \n",
    "        self.erpLayout = QVBoxLayout()\n",
    "    \n",
    "        # create directory box \n",
    "        self.dirLayout = QHBoxLayout()\n",
    "        dirLabel = QLabel('Directory: ')\n",
    "        self.dirInp = QLineEdit('dirs here')\n",
    "        self.dirLayout.addWidget(dirLabel)\n",
    "        self.dirLayout.addWidget(self.dirInp)\n",
    "        \n",
    "        # create experiment box \n",
    "        self.filesLayout = QHBoxLayout()\n",
    "        self.filesLabel = QLabel('Space-delimited exp names: ')\n",
    "        self.filesInp = QLineEdit('exps here')\n",
    "        self.filesLayout.addWidget(self.filesLabel)\n",
    "        self.filesLayout.addWidget(self.filesInp)\n",
    "        \n",
    "        # create target directory box \n",
    "        self.trgLayout = QHBoxLayout()\n",
    "        self.trgLabel = QLabel('Target Directory: ')\n",
    "        self.trgInp = QLineEdit('trg here')\n",
    "        self.trgLayout.addWidget(self.trgLabel)\n",
    "        self.trgLayout.addWidget(self.trgInp)\n",
    "        \n",
    "        #################################### ERP BUTTONS \n",
    "        # add create get h1's button\n",
    "        self.h1Button = QPushButton(\"Create h1 files\")\n",
    "        self.h1Button.clicked.connect(self.h1_handler)\n",
    "        \n",
    "        # add review site data button \n",
    "        self.reviewButton = QPushButton(\"Review Data\")\n",
    "        self.reviewButton.clicked.connect(self.review_handler)\n",
    "        \n",
    "        # add h1's in pwd button \n",
    "        self.h1PWDButton = QPushButton(\"Create h1 files in PWD\")\n",
    "        self.h1PWDButton.clicked.connect(self.h1PWD_handler)\n",
    "        \n",
    "\n",
    "        # add dirLayout, files layout, start buttons to nav layout \n",
    "        self.erpLayout.addLayout(self.dirLayout)\n",
    "        self.erpLayout.addLayout(self.filesLayout)\n",
    "        self.erpLayout.addLayout(self.trgLayout)\n",
    "        \n",
    "        # add buttons \n",
    "        self.erpLayout.addWidget(self.h1Button)\n",
    "        self.erpLayout.addWidget(self.reviewButton)\n",
    "        self.erpLayout.addWidget(self.h1PWDButton)\n",
    "        \n",
    "        # add nav layout to NAV TAB \n",
    "        self.h1Tab.setLayout(self.erpLayout)\n",
    "        \n",
    "        #################################### NEURO TAB ####################################\n",
    "        \n",
    "        # create vertical layout for neuropsych tab \n",
    "        self.neuroLayout = QVBoxLayout()\n",
    "    \n",
    "        # create directory box -- neuropsych \n",
    "        self.dirLayoutNeuro = QHBoxLayout()\n",
    "        dirLabelNeuro = QLabel('Directory: ')\n",
    "        self.dirInpNeuro = QLineEdit('dirs here')\n",
    "        self.dirLayoutNeuro.addWidget(dirLabelNeuro)\n",
    "        self.dirLayoutNeuro.addWidget(self.dirInpNeuro)\n",
    "        \n",
    "        # create month box -- neuropsych \n",
    "        self.monthLayoutNeuro = QHBoxLayout()\n",
    "        monthLabelNeuro = QLabel('Enter month as integer: ')\n",
    "        self.monthInpNeuro = QLineEdit('month here')\n",
    "        self.monthLayoutNeuro.addWidget(monthLabelNeuro)\n",
    "        self.monthLayoutNeuro.addWidget(self.monthInpNeuro)\n",
    "        \n",
    "        # create site box -- neuropsych \n",
    "        self.siteLayoutNeuro = QHBoxLayout()\n",
    "        siteLabelNeuro = QLabel('Enter site name: ')\n",
    "        self.siteInpNeuro = QLineEdit('site here')\n",
    "        self.siteLayoutNeuro.addWidget(siteLabelNeuro)\n",
    "        self.siteLayoutNeuro.addWidget(self.siteInpNeuro)\n",
    "        \n",
    "        # add directory, month, & site box to neuroLayout    \n",
    "        self.neuroLayout.addLayout(self.dirLayoutNeuro)\n",
    "        self.neuroLayout.addLayout(self.monthLayoutNeuro)\n",
    "        self.neuroLayout.addLayout(self.siteLayoutNeuro)\n",
    "        \n",
    "        # add neuroLayout to neuroTab\n",
    "        self.neuroTab.setLayout(self.neuroLayout)\n",
    "        \n",
    "        #################################### NEURO BUTTONS \n",
    "        # add check neuro raw data button \n",
    "        self.checkButtonNeuro = QPushButton(\"Check /raw_data/neuropsych/__sitename__\")\n",
    "        self.checkButtonNeuro.clicked.connect(self.check_neuro_handler)\n",
    "        \n",
    "        # add check for duplicates button \n",
    "        self.dupesButtonNeuro = QPushButton(\"Check for Duplicates\")\n",
    "        self.dupesButtonNeuro.clicked.connect(self.dupes_neuro_handler)\n",
    "        \n",
    "        # add neuro review button \n",
    "        self.reviewButtonNeuro = QPushButton(\"Run neuropsych check\")\n",
    "        self.reviewButtonNeuro.clicked.connect(self.review_neuro_handler)\n",
    "    \n",
    "        # add move neuro files button \n",
    "        self.moveButtonNeuro = QPushButton(\"MOVE files to /raw_data/neuropsych/__sitename__\")\n",
    "        self.moveButtonNeuro.clicked.connect(self.move_neuro_handler)\n",
    "        \n",
    "        # add buttons to neuroLayout\n",
    "        self.neuroLayout.addWidget(self.checkButtonNeuro)\n",
    "        self.neuroLayout.addWidget(self.dupesButtonNeuro)\n",
    "        self.neuroLayout.addWidget(self.reviewButtonNeuro)\n",
    "        self.neuroLayout.addWidget(self.moveButtonNeuro)\n",
    "        \n",
    "        \n",
    "        ############################################## end neuro tab \n",
    "        # Add tabs to tab widget \n",
    "        self.tabs.addTab(self.h1Tab,\"ERP\")\n",
    "        self.tabs.addTab(self.neuroTab,\"Neuropsych\")\n",
    "\n",
    "        \n",
    "        self.setCentralWidget(self.tabs)\n",
    "        self.show()\n",
    "        \n",
    "    ############################################## NEURO HANDLERS ##############################################\n",
    "    \n",
    "    def check_neuro_handler(self, signal):\n",
    "        \"\"\"Check to see if new neuropsych data already exists in /raw_data/neuropsych/__sitename__\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        siteInp = self.siteInpNeuro.text().strip()\n",
    "        # my script\n",
    "        np_run_exists(directoryInp, siteInp)\n",
    "        \n",
    "        \n",
    "    def dupes_neuro_handler(self, signal):\n",
    "        \"\"\"Check for duplicate files in new neuropsych data from site\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        # my script \n",
    "        md5_check_walk(directoryInp)\n",
    "        \n",
    "        \n",
    "    def review_neuro_handler(self, signal):\n",
    "        \"\"\"Check for file naming/xml inconsistencies in new neuropsych data from site\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        monthInp = self.monthInpNeuro.text().strip()\n",
    "        # my script \n",
    "        neuro(directoryInp, monthInp)\n",
    "        \n",
    "\n",
    "    def move_neuro_handler(self, signal):\n",
    "        \"\"\"only after the above 3 functions are run, move new site data to /raw_data/neuropsych/__sitename__\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        siteInp = self.siteInpNeuro.text().strip()\n",
    "        # my script\n",
    "        move_neuro_files(directoryInp, siteInp)\n",
    "        \n",
    "        \n",
    "    ############################################## ERP HANDLERS ##############################################\n",
    "    \n",
    "    def h1_handler(self, signal):\n",
    "        \"\"\" add a directories to exclude box?? \"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        directorytrg = self.trgInp.text().strip()\n",
    "        \n",
    "        \n",
    "        files = self.filesInp.text().strip()\n",
    "        files_lst = files.split(' ')\n",
    "        files_set = set(files_lst)\n",
    "        \n",
    "        dir_paths  = [os.path.join(r,n) for r,d,f in os.walk(directoryInp) for n in d]\n",
    "        \n",
    "        for i in dir_paths:\n",
    "            pick.get_h1s(i, files_set, trg_dir=directorytrg)\n",
    "            \n",
    "    def review_handler(self, signal):\n",
    "        \"\"\"copy class from site_data.py\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInp.text.strip()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def h1PWD_handler(self, signal):\n",
    "        \"\"\"add something here to differentiate between 1 directory & multiple directories??\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        files = self.filesInp.text().strip()\n",
    "        files_lst = files.split(' ')\n",
    "        files_set = set(files_lst)\n",
    "        \n",
    "        #dir_paths  = [os.path.join(r,n) for r,d,f in os.walk(p) for n in d]\n",
    "        \n",
    "        pick.get_h1s(directoryInp, files_set, ps=directoryInp)\n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app = QCoreApplication.instance() ### adding this if statement prevents kernel from crashing \n",
    "    if app is None:\n",
    "        app = QApplication(sys.argv)\n",
    "        print(app)\n",
    "    ex = App()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/vol01/active_projects/anthony/test_qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/vol01/active_projects/anthony/ns650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/dbI/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "/vol01/active_projects/anthony/ns650/40019004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/dbI/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "pp.get_h1s(fp, exp_set, del_ext=delext, ps=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create avg.h1 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import collections\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "class site_data:\n",
    "    #get_h1s()\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.ant_set = {'ant'}\n",
    "        self.ans_set = {'ans'}\n",
    "        self.other_exps = {'vp3', 'cpt', 'ern', 'aod', 'stp', 'gng'}\n",
    "        \n",
    "    #get_h1s()    \n",
    "    def check_cnt_copy(self, fp_check_cnt, exps_list):\n",
    "        \"\"\"\n",
    "        create dictionary of lists where id is key and exp*cnt names are the values\n",
    "        \"\"\"\n",
    "        self.fp_check_cnt = fp_check_cnt\n",
    "        self.exps_list = exps_list\n",
    "        \n",
    "    \n",
    "        cnt_dict = {}\n",
    "        for r,d,f in os.walk(fp_check_cnt):\n",
    "            for n in f:\n",
    "                if n.endswith('_32.cnt'):\n",
    "                    split = n.split('_')\n",
    "                    cnt_dict.setdefault(split[3], []).append(split[0])\n",
    "                    \n",
    "        return cnt_dict\n",
    "                    \n",
    "        for k,v in cnt_dict.items():\n",
    "            if len(v) != len(exps_list):\n",
    "                for missing in exps_list:\n",
    "                    if missing not in v:\n",
    "                        print(\"{} missing from {}'s folder\".format(missing, k))\n",
    "                \n",
    "    #get_h1s()   --NEED TO CHANGE THIS               \n",
    "    def rename_reruns(self, fp_rerun, fp_rerun_trg=None):\n",
    "        \"\"\"\n",
    "        if peak-picking, copy rr file to target directory and rename it.\n",
    "        if not peak-picking, only let me know there is a rr file\n",
    "        \"\"\"\n",
    "        self.fp_rerun = fp_rerun\n",
    "        self.fp_rerun_trg = fp_rerun_trg\n",
    "        \n",
    "        #check for _rr.cnt regardless of run number \n",
    "        for r,d,f in os.walk(fp_rerun):\n",
    "            for n in f:\n",
    "                if n.endswith('_rr.cnt'):\n",
    "                    print('Found re-runs...',  os.path.basename(fp_rerun), n)\n",
    "                    answer=input('Copy to target directory?')\n",
    "                    if answer in ['y', 'Y', 'yes', 'Yes']:\n",
    "                        shutil.copy(os.path.join(r,n), os.path.join(fp_rerun_trg, n[:3])) \n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "        #rename only if peak picking              \n",
    "        if fp_rerun_trg:\n",
    "            for r,d,f in os.walk(fp_rerun_trg):\n",
    "                for n in f:\n",
    "                    if n.endswith('_rr.cnt'):\n",
    "                        new_name = os.rename(os.path.join(r, n), os.path.join(r,n.replace(\"_rr\", \"\")))\n",
    "                        print('\\n', 'Renaming', os.path.join(r,n), '\\n', \n",
    "                              'to','\\n', os.path.join(r,n.replace(\"_rr\", \"\"), '\\n'))\n",
    "                        \n",
    "    #get_h1s()                    \n",
    "    def create_cnth1(self, fp_cnt):\n",
    "        \"\"\"\n",
    "        .cnt => .cnt.h1\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fp_cnt = fp_cnt\n",
    "        \n",
    "        print('\\n', '_________________________________________________CREATING CNT.H1S_________________________________________________')\n",
    "        for r,d,f in os.walk(fp_cnt):\n",
    "            for n in f:\n",
    "                if n.startswith(self.cnth1_tups) and n.endswith('_32.cnt'):\n",
    "                    path = os.path.join(r,n)\n",
    "                    p = subprocess.Popen(\"create_cnthdf1_from_cntneuroX.sh {}\".format(path),shell=True, \n",
    "                                          stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(path))\n",
    "                    result = p.communicate()[1]\n",
    "                    print(result.decode('ascii'))\n",
    "                    \n",
    "    #get_h1s()                \n",
    "    def create_avgh1(self, fp_h1):\n",
    "        \"\"\"\n",
    "        .cnt.h1 => .avg.h1\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fp_h1 = fp_h1\n",
    "\n",
    "        print('\\n', '_________________________________________________CREATING AVG.H1_________________________________________________')            \n",
    "        for r,d,f in os.walk(fp_h1):\n",
    "            for n in f:\n",
    "                if n.startswith(self.ant_tup) and n.endswith('cnt.h1'):\n",
    "                    ant_path = os.path.join(r,n)\n",
    "                    p_ant = subprocess.Popen('create_avghdf1_from_cnthdf1X -lpfilter 8 -hpfilter 0.03 -thresh 75 -baseline_times -125 0 {}'.format(ant_path), \n",
    "                                             shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(ant_path))\n",
    "                    result_ant = p_ant.communicate()[1]\n",
    "                    print(result_ant.decode('ascii'))\n",
    "                if n.startswith(self.ans_tup) and n.endswith('cnt.h1'):\n",
    "                    ans_path = os.path.join(r,n)\n",
    "                    p_ans = subprocess.Popen('create_avghdf1_from_cnthdf1X -lpfilter 16 -hpfilter 0.03 -thresh 100 -baseline_times -125 0 {}'.format(ans_path), \n",
    "                                            shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(ans_path))\n",
    "                    result_ans = p_ans.communicate()[1]\n",
    "                    print(result_ans.decode('ascii'))\n",
    "                if n.startswith((self.others_tup)) and n.endswith('cnt.h1'):\n",
    "                    path=os.path.join(r,n)\n",
    "                    p_others = subprocess.Popen('create_avghdf1_from_cnthdf1X -lpfilter 16 -hpfilter 0.03 -thresh 75 -baseline_times -125 0 {}'.format(path), \n",
    "                                                shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(path))\n",
    "                    result_others = p_others.communicate()[1]\n",
    "                    print(result_others.decode('ascii'))\n",
    "                    \n",
    "                    \n",
    "    #get_h1s()\n",
    "    def create_avgps(self, fp_ps):\n",
    "        \"\"\"\n",
    "        avg.h1 => avg.h1.ps in pwd\n",
    "        \"\"\"\n",
    "        self.fp_ps = fp_ps\n",
    "\n",
    "        print('\\n', '_________________________________________________CREATE H1.PS_________________________________________________')\n",
    "        \n",
    "        for path, subdirs, files in os.walk(fp_ps):\n",
    "            for name in files:\n",
    "                if name.endswith(\"avg.h1\"):\n",
    "                    ps_paths = os.path.join(path, name)\n",
    "                    subprocess.Popen(\"plot_hdf1_data.sh {}\".format(name), shell=True, cwd=os.path.dirname(ps_paths))\n",
    "                    print(\"Creating ps files...  {}\".format(name))\n",
    "                    \n",
    "    #get_h1s()                \n",
    "    def delete_bad_files(self, fp):\n",
    "        \"\"\"\n",
    "        returns any extension not in exts_to_keep & prompts user to delete \n",
    "        \"\"\"\n",
    "        self.fp = fp\n",
    "\n",
    "        print('\\n', '_________________________________________________CLEANING UP...________________________________________________')\n",
    "    \n",
    "        for r,d,f in os.walk(fp):\n",
    "            for n in f:\n",
    "                if n.endswith(('_32.cnt', '_cnt.h1')):\n",
    "                    os.remove(os.path.join(r,n))\n",
    "                    print(\"\\nRemoving {}\\n\".format(n))\n",
    "                        \n",
    "    def get_h1s(self, fp, set_of_exps, ps=None, trg_dir=None):\n",
    "        \"\"\"\n",
    "        combines all these commands together\n",
    "        \"\"\"\n",
    "        self.fp = fp\n",
    "        self.set_of_exps = set_of_exps\n",
    "        self.ps = ps\n",
    "        self.trg_dir = trg_dir\n",
    "        \n",
    "        #use in create_cnth1()\n",
    "        self.cnth1_tups = tuple(set_of_exps)\n",
    "        \n",
    "        if_ant = self.ant_set & set_of_exps\n",
    "        if_ans = self.ans_set & set_of_exps\n",
    "        all_others = self.other_exps & set_of_exps\n",
    "        \n",
    "        #used in create_avgh1()\n",
    "        self.ant_tup = tuple(if_ant)\n",
    "        self.ans_tup = tuple(if_ans)\n",
    "        self.others_tup = tuple(all_others)\n",
    "\n",
    "        #if being used for peak picking, create new directories and move all cnt files to the correct folder...and so on\n",
    "        if trg_dir:\n",
    "            #create new directories\n",
    "            exps_list = list(set_of_exps)\n",
    "            for exp in exps_list:\n",
    "                new_dirs = os.path.join(trg_dir, exp)\n",
    "                if not os.path.exists(new_dirs):\n",
    "                    os.makedirs(new_dirs)\n",
    "                    print(\"Creating {}\\n\".format(new_dirs))\n",
    "                else:\n",
    "                    print(\"{} already exist\\n\".format(new_dirs))\n",
    "            #copy cnt files to newly created directories       \n",
    "            count = 0\n",
    "            for r,d,f in os.walk(fp):\n",
    "                for n in f:\n",
    "                    if n.startswith(self.cnth1_tups) and n.endswith('_32.cnt'):\n",
    "                        count+=1\n",
    "                        print(\"Copying {}\".format(n))\n",
    "                        shutil.copy(os.path.join(r,n), os.path.join(trg_dir, n[:3]))\n",
    "                        if count % len(exps_list) == 0:\n",
    "                            print('\\n')\n",
    "            print(\"\\nCopied {} files.\\n\".format(count))\n",
    "                        \n",
    "            self.rename_reruns(fp,fp_rerun_trg=trg_dir)\n",
    "            self.check_cnt_copy(trg_dir, exps_list)\n",
    "            self.create_cnth1(trg_dir)\n",
    "            self.create_avgh1(trg_dir)\n",
    "            self.delete_bad_files(trg_dir)\n",
    "            if ps:\n",
    "                self.create_avgps(trg_dir)\n",
    "            return True\n",
    "        \n",
    "        \n",
    "        exps_list = list(set_of_exps)\n",
    "        #if you want to create avg.h1s IN directory copying files...\n",
    "        self.check_cnt_copy(fp, exps_list)\n",
    "        self.rename_reruns(fp)\n",
    "        self.create_cnth1(fp)\n",
    "        self.create_avgh1(fp)\n",
    "        \n",
    "        for r,d,f in os.walk(fp):\n",
    "            for n in f:\n",
    "                if n.endswith(('_cnt.h1')):\n",
    "                    remove_path = os.path.join(r,n)\n",
    "                    print(\"Removing {}\".format(remove_path))\n",
    "                \n",
    "        if ps:\n",
    "            self.create_avgps(fp)\n",
    "pick = site_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = '/vol01/active_projects/anthony/ns650/40115162'\n",
    "exps = {'ant', 'aod'}\n",
    "\n",
    "pick.get_h1s(p, exps, ps=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check to see if new site data already exists in /raw_data/...  (e.g. duplicate run letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def np_run_exists(path_to_new_data, site):\n",
    "    '''given a path to new data and str(site) -- \n",
    "       tells if file already exists in directory'''\n",
    "    \n",
    "    np_basename = '/vol01/raw_data/neuropsych/'\n",
    "    \n",
    "    files = []\n",
    "    for r,d,f in os.walk(path_to_new_data):\n",
    "        for n in f:\n",
    "            files.append(n)\n",
    "            \n",
    "         \n",
    "    np_full_path = np_basename + site\n",
    "    \n",
    "    duplicate_files = []  \n",
    "    for r,d,f in os.walk(np_full_path):\n",
    "        for n in f:\n",
    "            if n in files:\n",
    "                path = os.path.join(r,n)\n",
    "                duplicate_files.append(path)\n",
    "    \n",
    "    if len(duplicate_files) == 0:\n",
    "        print('All files are unique')\n",
    "    else:\n",
    "        #pass\n",
    "        print('im here')\n",
    "        #print('The following files already exist in', np_full_path, ' --->\\n\\n', [i for i in duplicate_files])\n",
    "    return duplicate_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check new neuropsych site data for duplicates before adding to /raw_data/neuropsych/__sitename__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import os \n",
    "\n",
    "def md5(path):\n",
    "    '''generate md5 - -read file in binary mode'''\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        md5_return = hashlib.md5(data).hexdigest()\n",
    "        return md5_return\n",
    "    \n",
    "    \n",
    "    \n",
    "def md5_check_walk(dir_path):\n",
    "    '''given a dir path -- comapres md5 checksums across files and identifies duplicate files '''\n",
    "    md5_dict = defaultdict(list)\n",
    "    for r,d,f in os.walk(dir_path):\n",
    "        for n in f:\n",
    "            fp = os.path.join(r,n)\n",
    "            md5_dict[md5(fp)].append(fp)\n",
    "            \n",
    "    for k,v in md5_dict.items():\n",
    "        if len(v) > 1:  #multiple values for the same key\n",
    "            print(len(v), 'Duplicate files:', v,'\\n\\n\\n', 'with checksum', '\\n', k)\n",
    "        elif len(v) < 1:\n",
    "            print('No duplicates found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for inconsistencies in neuropsych file naming/xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "def restart_script():\n",
    "    input('Please fix then press enter to restart program')\n",
    "    neuro(fp)\n",
    "    \n",
    "def check_dict_len(dictionary, len_to_check):\n",
    "    '''used to check whether a file is empty or not '''\n",
    "    \n",
    "    for k,v in dictionary.items():\n",
    "        if len(v) < len_to_check:\n",
    "            print('Error:', k, 'is likely an empty file')\n",
    "    \n",
    "def neuro(fp, month_as_int):\n",
    "    \n",
    "    #1 -- check for unknown file types\n",
    "    for r,d,f in os.walk(fp):\n",
    "        for n in f:\n",
    "            if not n.endswith((\"xml\", \"txt\", \"_sum.txt\")):\n",
    "                path  = os.path.join(r,n)\n",
    "                print('\\n', 'Error: Unknown file types found --', path)\n",
    "                #restart_script()\n",
    "\n",
    "\n",
    "    #2 -- check that all IDS have 8 numbers and all sum/txt files having CBST/TOLT in filename\n",
    "    for r,d, f in os.walk(fp):\n",
    "        for n in f:\n",
    "            if n.endswith((\"_sum.txt\", 'txt')):\n",
    "                split = n.split(\"_\")\n",
    "                if len(split[0]) != 8:\n",
    "                    print('Error: ID Incorrect Length -- ', split)\n",
    "                    restart_script()\n",
    "                else:\n",
    "                    if split[1] == 'CBST':\n",
    "                        pass\n",
    "                    elif split[1] == 'TOLT':\n",
    "                        pass\n",
    "                    else:\n",
    "                        print('Error: Wrong experiment name -- ', split[0])\n",
    "                        #restart_script()\n",
    "                        \n",
    "    # 3 -- check for empty files                     \n",
    "    xml_size_dict = {}\n",
    "    txt_size_dict = {}\n",
    "    for r,d,f in os.walk(fp):\n",
    "        for n in f:\n",
    "            if n.endswith('xml'):\n",
    "                with open(os.path.join(r,n), 'r') as file:\n",
    "                    for xml_line in file:\n",
    "                        path_xml= os.path.join(r,n)\n",
    "                        xml_size_dict.setdefault(path_xml, []).append(xml_line)\n",
    "            if n.endswith(('txt', '_sum.txt')):\n",
    "                with open(os.path.join(r,n), 'r') as file_txt:\n",
    "                    for txt_line in file_txt:\n",
    "                        path_txt= os.path.join(r,n)\n",
    "                        txt_size_dict.setdefault(path_txt, []).append(txt_line)\n",
    "\n",
    "    check_dict_len(xml_size_dict, 3)\n",
    "\n",
    "    check_dict_len(txt_size_dict, 3)\n",
    "\n",
    "    #4 -- create dictionary of each element in the filename \n",
    "    sum_txt_dict = {}\n",
    "    txt_dict = {}\n",
    "    xml_fname_dict = {}\n",
    "\n",
    "    for r,d,f in os.walk(fp):\n",
    "        ids_sumtxt = []\n",
    "        version_sumtxt = []\n",
    "        run_sumtxt = []\n",
    "        ext_sumtxt = []\n",
    "\n",
    "        ids_txt=[]\n",
    "        version_txt = []\n",
    "        run_txt = []\n",
    "        ext_txt = []\n",
    "\n",
    "\n",
    "        ids_xml = []\n",
    "        run_xml = []\n",
    "        ext_xml = []\n",
    "        for n in f:\n",
    "            if n.endswith('txt'):\n",
    "                if n.endswith('_sum.txt'):\n",
    "                    sumtxt_split = n.split('_')\n",
    "                    ids_sumtxt.append(sumtxt_split[0])\n",
    "                    version_sumtxt.append(sumtxt_split[2])\n",
    "                    run_sumtxt.append(sumtxt_split[3])\n",
    "                    ext_sumtxt.append(sumtxt_split[-1])\n",
    "                else:\n",
    "                    txt_split = re.split(r'[_.]', n)\n",
    "                    ids_txt.append(txt_split[0])\n",
    "                    version_txt.append(txt_split[2])\n",
    "                    run_txt.append(txt_split[3])\n",
    "                    ext_txt.append(txt_split[-1])\n",
    "            if n.endswith('xml'):\n",
    "                xml_split = n.split('_')\n",
    "                ids_xml.append(xml_split[0])\n",
    "                run_xml.append(xml_split[1])\n",
    "                ext_xml.append(xml_split[2])\n",
    "\n",
    "        tup_sumtxt = version_sumtxt, run_sumtxt, ext_sumtxt\n",
    "        tup_txt = version_txt, run_txt, ext_txt\n",
    "        tup_xml = run_xml, ext_xml\n",
    "\n",
    "        for i in ids_sumtxt:\n",
    "            sum_txt_dict[i] = tup_sumtxt\n",
    "\n",
    "        for j in ids_txt:\n",
    "            txt_dict[j] = tup_txt\n",
    "\n",
    "        for k in ids_xml:\n",
    "            xml_fname_dict[i] = tup_xml \n",
    "\n",
    "        ids_total = ids_sumtxt + ids_txt + ids_xml\n",
    "        ids_count_dict = Counter(ids_total)\n",
    "        for k,v in ids_count_dict.items():\n",
    "            if v != 5:\n",
    "                print('Error: There\\'s an ID missing from', k)\n",
    "                #restart_script()\n",
    "\n",
    "    #####might need to add check to make sure sum_txt & txt dict keys are same length???\n",
    "\n",
    "    #5 -- check for version, run leter, and # of extensions for sum_txt files \n",
    "    for k,v in sum_txt_dict.items():\n",
    "        if len(list(set(v[0]))) != 1:\n",
    "            print('Error: Check version number for sum_txt file', k)\n",
    "        for i in v[0]:\n",
    "            if i != '1':\n",
    "                print('Error: Check version number for sum_txt file', k)\n",
    "        if len(list(set(v[1]))) != 1:\n",
    "            print('Error: Check run letter for sum_txt file', k)\n",
    "            restart_script()\n",
    "        if len(v[2]) != 2:\n",
    "            print('Error: Missing sum_txt file for ID', k)\n",
    "\n",
    "\n",
    "    #6 -- check for version, run leter, and # of extensions for txt files \n",
    "    for k,v in txt_dict.items():\n",
    "        if len(list(set(v[0]))) != 1:\n",
    "            print('Error: Check version number for txt file', k)\n",
    "        for i in v[0]:\n",
    "            if i != '1':\n",
    "                print('Error: Check version number for txt file', k)\n",
    "        if len(list(set(v[1]))) != 1:\n",
    "            print('Error: Check run letter for txt file', k)\n",
    "            restart_script()\n",
    "        if len(v[2]) != 2:\n",
    "            print('Error: Missing txt file for ID txt file', k)\n",
    "\n",
    "\n",
    "    #7 -- check to see if version and run letter are identical across txt & sum_txt files\n",
    "    for k,v in sum_txt_dict.items():\n",
    "        if k in txt_dict.keys():\n",
    "            if not v[0] == txt_dict[k][0]:\n",
    "                print('Error: Version number between sum.txt & txt files don\\'t match for', k)\n",
    "            if not v[1]  == txt_dict[k][1]:\n",
    "                print('Error: Run letter between sum.txt & txt files don\\'t match for', k)\n",
    "                restart_script()\n",
    "\n",
    "    #8 -- check for things inside xml file            \n",
    "    xml = [os.path.join(root,name) for root,dirs,files in os.walk(fp) for name in files if name.endswith(\".xml\")]\n",
    "\n",
    "    within_xml_id = []\n",
    "    within_xml_run = []\n",
    "    xml_motiv = []\n",
    "\n",
    "\n",
    "    xml_dict_new = {}\n",
    "    for i in xml:\n",
    "        lst_xml_id = []\n",
    "        dob_lst = []\n",
    "        testdate_lst = []\n",
    "        gender_lst = []\n",
    "        hand_lst = []\n",
    "        with open(i) as f:\n",
    "            for line in f:\n",
    "                if line.startswith('  <Sub'):\n",
    "                    lst_xml_id.extend(re.findall(r'<SubjectID>(.*?)</SubjectID>', line))\n",
    "                    within_xml_id.extend(re.findall(r'<SubjectID>(.*?)</SubjectID>', line))\n",
    "                if line.startswith('  <Sess'):\n",
    "                    within_xml_run.extend(re.findall(r'<SessionCode>(.*?)</SessionCode>', line))\n",
    "                if line.startswith('  <Motivation>'):\n",
    "                    xml_motiv.extend(re.findall(r'<Motivation>(.*?)</Motivation>', line))\n",
    "                if line.startswith('  <DOB>'):\n",
    "                    dob_lst.extend(re.findall(r'<DOB>(.*?)</DOB>', line))\n",
    "                if line.startswith('  <TestDate>'):\n",
    "                    testdate_lst.extend(re.findall(r'<TestDate>(.*?)</TestDate>', line))\n",
    "                if line.startswith('  <Gender>'):\n",
    "                    gender_lst.extend(re.findall(r'<Gender>(.*?)</Gender>', line))\n",
    "                if line.startswith('  <Hand>'):\n",
    "                    hand_lst.extend(re.findall(r'<Hand>(.*?)</Hand>', line))\n",
    "                    \n",
    "                xml_tuples = dob_lst, testdate_lst, gender_lst, hand_lst\n",
    "                for i in lst_xml_id:\n",
    "                    xml_dict_new[i] = xml_tuples\n",
    "                    \n",
    "    now = datetime.datetime.now().year\n",
    "    \n",
    "\n",
    "    #9 -- xml check for accurate DOB, testdate, & that gender and version start with uppercase letter\n",
    "    for k,v in xml_dict_new.items():\n",
    "        for i in v[0]:\n",
    "            date_split = i.split('/')\n",
    "            year = int(date_split[-1])\n",
    "            if year > 2015:\n",
    "                print('Error: Check DOB in xml file for', k)\n",
    "        for j in v[1]:\n",
    "            testdate_split = j.split('/')\n",
    "            year_test = int(testdate_split[-1])\n",
    "            if year_test != now:\n",
    "                print('Error: Check test date in xml file for', k)\n",
    "            if int(month_as_int) != int(testdate_split[0]):\n",
    "                print('Error: Month of test date in xml file incorrect for', k )\n",
    "        for l in v[2]:\n",
    "            if not l[0].isupper(): #maybe str.istitle() would be better?\n",
    "                print('Error: Make gender uppercase in xml file for', k)\n",
    "        for m in v[3]:\n",
    "            if not m[0].isupper():\n",
    "                print('Error: Make handedness uppercase in xml file for', k)\n",
    "\n",
    "    inside_xml = dict(zip(within_xml_id, within_xml_run))\n",
    "\n",
    "    #10 -- xml check for length of sub IDs \n",
    "    xml_ids = [('Error: Check inside xml file for sub ID', i) for i in within_xml_id if len(i) != 8]\n",
    "    if len(xml_ids) != 0:\n",
    "        print(xml_ids)\n",
    "\n",
    "    #11 -- 12 will only work if 2 xml dicts have the same keys \n",
    "    missing_xml_keys = set(xml_fname_dict.keys() ^ inside_xml.keys())\n",
    "    \n",
    "    if len(list(missing_xml_keys)) > 0:\n",
    "        print('Error: Check', missing_xml_keys, 'folder for missing xml files/'\n",
    "              'incorrect sub ID within xml file' )\n",
    "        restart_script()\n",
    "\n",
    "    #12 -- check to see if run letter within xml matches xml filename    \n",
    "    for k,v in xml_fname_dict.items():\n",
    "        for l in v[0]:\n",
    "            if k in inside_xml.keys():\n",
    "                if l not in inside_xml[k]:\n",
    "                    print('Error: Check', k, 'folder for mismatch between xml run letter and xml filename run letter')\n",
    "                    restart_script()\n",
    "\n",
    "    #13 -- since we know txt & sum_txt run letters are identical & that inside and xml fname run letters are identical...\n",
    "    #13... check run letters against xml & sum_txt files \n",
    "    for k,v in txt_dict.items():\n",
    "        run_letter = v[1][0][0]\n",
    "        if k in inside_xml.keys():\n",
    "            if run_letter not in inside_xml.values():\n",
    "                print('Error: Check', k, 'folder for mismatch between xml run letter and xml filename run letter')\n",
    "                restart_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move neuropsych files from pwd to /raw_data/neuropsych/__sitename__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "def move_neuro_files(new_site_data, site_name):\n",
    "    \"\"\"\n",
    "    given a path to incoming neuropsych data, moves files to correct directory in /raw_data/neuropsych/\n",
    "    data must be checked with .exe files before moving. \n",
    "    \n",
    "    new_site_data = path on server to new np data\n",
    "    site_name = double check for correct site directory \n",
    "    \"\"\"\n",
    "    full_neuro_path = '/vol01/raw_data/neuropsych/' + site_name\n",
    "    \n",
    "    if not os.path.exists(full_neuro_path):\n",
    "        print(\"{} doesn't exist...exiting\".format(full_neuro_path))\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # get dir names from neuropsych disc\n",
    "    disc_dir_names = []\n",
    "    for r,d,f in os.walk(new_site_data):\n",
    "        for n in d:\n",
    "            disc_dir_names.append(n)\n",
    "                \n",
    "    # to search dirs from neuropsych disc on server to see if they exist \n",
    "    dirs_exist = []\n",
    "    for i in disc_dir_names:\n",
    "        neuro_dirs = glob(full_neuro_path)\n",
    "        for nd in neuro_dirs:\n",
    "            if os.path.exists(nd) == True:\n",
    "                dirs_exist.append(nd)\n",
    "\n",
    "    # here are the dirs from disc that exist on server\n",
    "    dirs_found = [i.split('/')[-1] for i in dirs_exist]\n",
    "    \n",
    "    # here are the dirs that need to be created\n",
    "    to_be_created = set(disc_dir_names) ^ set(dirs_found)\n",
    "    \n",
    "    # zip lengths MUST BE EQUAL -- for all the dirs that were found, multiply by 5\n",
    "    dirs_found_concat = ['/raw_data/neuropsych/'+ site_name + '/' + i for i in dirs_found]\n",
    "    dirs_exist_all = sorted(dirs_found_concat *5)\n",
    "    \n",
    "    \n",
    "    # get all files from disc of dirs that were found on server ==> dirs exist\n",
    "    files_to_move = []\n",
    "    for r,d,f in os.walk(new_site_data):\n",
    "        for n in d:\n",
    "            if n in dirs_found:\n",
    "                path = os.path.join(r,n)\n",
    "                files = os.listdir(path)\n",
    "                for fi in files:\n",
    "                    goods = r + '/'+ n + '/' + fi\n",
    "                    files_to_move.append(goods)\n",
    "                    \n",
    "    # check for dirs exist\n",
    "    if len(dirs_exist_all)!= len(files_to_move):\n",
    "        print('STOP RIGHT NOW')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # create directories for all new neuro subs -- dirs don't exist \n",
    "    # if \n",
    "    new_dirs = []\n",
    "    if len(list(to_be_created)) != 0:\n",
    "        for i in list(to_be_created):\n",
    "            new_dir = ['/raw_data/neuropsych/'+ site_name + '/' + i]\n",
    "            for dirs in new_dir:\n",
    "                if os.path.exists(dirs):\n",
    "                    print('dir already exists,.. closing')\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    os.makedirs(dirs)\n",
    "                    print('making new dir...\\n{}\\n'.format(dirs))\n",
    "                    new_dirs.append(dirs) \n",
    "                    \n",
    "    # prep new dirs for zip & get SUB ID  -- dirs that dont exist \n",
    "    new_dirs_server = new_dirs *5   \n",
    "    new_dir_check = []\n",
    "    for i in new_dirs_server:\n",
    "        new_d = i.split('/')[-1]\n",
    "        new_dir_check.append(new_d)\n",
    "        \n",
    "    # check new site data for dirs with name that isn't found on server  -- dirs that dont exist \n",
    "    files_to_be_added = []\n",
    "    for r,d,f in os.walk(new_site_data):\n",
    "        for n in d:\n",
    "            if n in list(set(new_dir_check)):\n",
    "                good_dir = os.path.join(r,n)\n",
    "                to_be_added = os.listdir(good_dir)\n",
    "                for i in to_be_added:\n",
    "                    full_paths = good_dir +'/'+ i\n",
    "                    files_to_be_added.append(full_paths)\n",
    "\n",
    "                    \n",
    "    # key is neuropsych dir on server & values are full paths to site data files \n",
    "    neuro_dict = {}\n",
    "    for server, site in zip(sorted(dirs_exist_all), sorted(files_to_move)):\n",
    "        neuro_dict.setdefault(server, []).append(site)\n",
    "        \n",
    "    # this is for NEWLY created dirs \n",
    "    neuro_dict_to_be_added = {}\n",
    "    for server, site in zip(sorted(new_dirs_server), sorted(files_to_be_added)):\n",
    "        neuro_dict_to_be_added.setdefault(server, []).append(site)\n",
    "\n",
    "    neuro_dict.update(neuro_dict_to_be_added)\n",
    "    \n",
    "    # move some stuff\n",
    "    count = 0\n",
    "    for x in range(len(neuro_dict)):\n",
    "        for idx, (k,v) in enumerate(neuro_dict.items()):\n",
    "            check_server = k.split('/')[-1]\n",
    "            if idx % 5 == 0:\n",
    "                count+=1\n",
    "                input('\\n\\nPress enter to start moving files in sets of 5.\\n\\n')\n",
    "            if idx == x:\n",
    "                for i in v:\n",
    "                    fname = os.path.basename(i)\n",
    "                    trg = k +'/' + fname\n",
    "                    if not os.path.exists(trg):\n",
    "                        shutil.move(i, trg)\n",
    "                        print('\\nSource - {}\\nDestination - {}\\n'.format(i, trg))\n",
    "                    else:\n",
    "                        print(i)\n",
    "                        ans = input('\\nThis file above already exists.\\nEnter \"i\" to ignore or \"q\" to quit\\n')\n",
    "                        if 'i' in ans:\n",
    "                            pass\n",
    "                        else:\n",
    "                            print('closing down...')\n",
    "                            sys.exit(1)\n",
    "\n",
    "                \n",
    "    print('\\n\\nTotal of {} subjects moved from {} to {}\\n\\n'.format(count, full_neuro_path, new_site_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/dbI/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# dont fuggin touch -- ONLY WORKING VERSION \n",
    "\n",
    "import sys\n",
    "from PyQt5.QtWidgets import (QMainWindow, QApplication, QPushButton, QWidget, QAction, \n",
    "                             QTabWidget,QVBoxLayout, QHBoxLayout, QInputDialog, QLineEdit, QLabel,\n",
    "                             QFileDialog, QMainWindow, QPushButton)\n",
    "from PyQt5.QtGui import QIcon\n",
    "from PyQt5.QtCore import pyqtSlot, QCoreApplication\n",
    "\n",
    "          \n",
    "    \n",
    "class App(QMainWindow):        \n",
    " \n",
    "    def __init__(self):   \n",
    "        super(App, self).__init__()\n",
    "        \n",
    "        self.title = 'Site Data Utilities'\n",
    "        self.left = 0\n",
    "        self.top = 0\n",
    "        self.width = 600\n",
    "        self.height = 400\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        \n",
    " \n",
    "        # Initialize tab widget\n",
    "        self.tabs = QTabWidget()\n",
    "        \n",
    "        # create tabs \n",
    "        self.h1Tab = QWidget()\n",
    "        self.neuroTab = QWidget()\n",
    "        \n",
    "        # create vertical layout for navigation tab \n",
    "        self.erpLayout = QVBoxLayout()\n",
    "    \n",
    "        # create directory box \n",
    "        self.dirLayout = QHBoxLayout()\n",
    "        dirLabel = QLabel('Directory: ')\n",
    "        self.dirInp = QLineEdit('dirs here')\n",
    "        self.dirLayout.addWidget(dirLabel)\n",
    "        self.dirLayout.addWidget(self.dirInp)\n",
    "        \n",
    "        # create experiment box \n",
    "        self.filesLayout = QHBoxLayout()\n",
    "        self.filesLabel = QLabel('Space-delimited exp names: ')\n",
    "        self.filesInp = QLineEdit('exps here')\n",
    "        self.filesLayout.addWidget(self.filesLabel)\n",
    "        self.filesLayout.addWidget(self.filesInp)\n",
    "        \n",
    "        # create target directory box \n",
    "        self.trgLayout = QHBoxLayout()\n",
    "        self.trgLabel = QLabel('Target Directory: ')\n",
    "        self.trgInp = QLineEdit('trg here')\n",
    "        self.trgLayout.addWidget(self.trgLabel)\n",
    "        self.trgLayout.addWidget(self.trgInp)\n",
    "        \n",
    "        \n",
    "        # create get h1's button\n",
    "        self.h1Button = QPushButton(\"Create h1 files\")\n",
    "        self.h1Button.clicked.connect(self.h1_handler)\n",
    "        \n",
    "        # review site data button \n",
    "        self.reviewButton = QPushButton(\"Review Data\")\n",
    "        self.reviewButton.clicked.connect(self.review_handler)\n",
    "        \n",
    "    \n",
    "        # h1's in pwd button \n",
    "        self.h1PWDButton = QPushButton(\"Create h1 files in PWD\")\n",
    "        self.h1PWDButton.clicked.connect(self.h1PWD_handler)\n",
    "        \n",
    "\n",
    "        # add dirLayout, files layout, start buttons to nav layout \n",
    "        self.erpLayout.addLayout(self.dirLayout)\n",
    "        self.erpLayout.addLayout(self.filesLayout)\n",
    "        self.erpLayout.addLayout(self.trgLayout)\n",
    "        \n",
    "        # add buttons \n",
    "        self.erpLayout.addWidget(self.h1Button)\n",
    "        self.erpLayout.addWidget(self.reviewButton)\n",
    "        self.erpLayout.addWidget(self.h1PWDButton)\n",
    "        \n",
    "        # add nav layout to NAV TAB \n",
    "        self.h1Tab.setLayout(self.erpLayout)\n",
    "    \n",
    "        # Add tabs to tab widget \n",
    "        self.tabs.addTab(self.h1Tab,\"ERP\")\n",
    "        self.tabs.addTab(self.neuroTab,\"Neuropsych\")\n",
    "\n",
    "        \n",
    "        self.setCentralWidget(self.tabs)\n",
    "        self.show()\n",
    "        \n",
    "        #self.print_stuff()\n",
    "        \n",
    "    def h1_handler(self, signal):\n",
    "        \n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        directorytrg = self.trgInp.text().strip()\n",
    "        \n",
    "        \n",
    "        files = self.filesInp.text().strip()\n",
    "        files_lst = files.split(' ')\n",
    "        files_set = set(files_lst)\n",
    "        \n",
    "        dir_paths  = [os.path.join(r,n) for r,d,f in os.walk(directoryInp) for n in d]\n",
    "        \n",
    "        for i in dir_paths:\n",
    "            pick.get_h1s(i, files_set, trg_dir=directorytrg)\n",
    "            \n",
    "    def review_handler(self, signal):\n",
    "        \"\"\"copy class from site_data.py\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInp.text.strip()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def h1PWD_handler(self, signal):\n",
    "        \"\"\"add something here to differentiate between 1 directory & multiple directories??\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        files = self.filesInp.text().strip()\n",
    "        files_lst = files.split(' ')\n",
    "        files_set = set(files_lst)\n",
    "        \n",
    "        #dir_paths  = [os.path.join(r,n) for r,d,f in os.walk(p) for n in d]\n",
    "        \n",
    "        pick.get_h1s(directoryInp, files_set, ps=directoryInp)\n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app = QCoreApplication.instance() ### adding this if statement prevents kernel from crashing \n",
    "    if app is None:\n",
    "        app = QApplication(sys.argv)\n",
    "        print(app)\n",
    "    ex = App()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dbI]",
   "language": "python",
   "name": "conda-env-dbI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
