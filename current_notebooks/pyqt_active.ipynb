{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import (QMainWindow, QApplication, QPushButton, QWidget, QAction, \n",
    "                             QTabWidget,QVBoxLayout, QHBoxLayout, QInputDialog, QLineEdit, QLabel,\n",
    "                             QFileDialog, QMainWindow, QPushButton, QTextEdit, QMessageBox)\n",
    "from PyQt5.QtGui import QIcon, QTextCursor\n",
    "from PyQt5.QtCore import pyqtSlot, QCoreApplication, QProcess, QObject, pyqtSignal\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmittingStream(QObject):\n",
    "\n",
    "    textWritten = pyqtSignal(str)\n",
    "\n",
    "    def write(self, text):\n",
    "\n",
    "        self.textWritten.emit(str(text))\n",
    "    \n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "class App(QMainWindow):        \n",
    " \n",
    "    def __init__(self):   \n",
    "        super(App, self).__init__()\n",
    "        \n",
    "        self.title = 'Site Data Utilities'\n",
    "        self.left = 0\n",
    "        self.top = 0\n",
    "        self.width = 600\n",
    "        self.height = 400\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setWindowIcon(QIcon('/vol01/active_projects/anthony/brain.jpg'))\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        \n",
    " \n",
    "        # Initialize tab widget\n",
    "        self.tabs = QTabWidget()\n",
    "        \n",
    "        # create tabs \n",
    "        self.h1Tab = QWidget()\n",
    "        self.neuroTab = QWidget()\n",
    "        self.redirectTab = QWidget()\n",
    "        \n",
    "        #################################### ERP TAB ####################################\n",
    "        \n",
    "        # create vertical layout for ERP tab \n",
    "        self.erpLayout = QVBoxLayout()\n",
    "    \n",
    "        # create directory box \n",
    "        self.dirLayout = QHBoxLayout()\n",
    "        dirLabel = QLabel('Directory: ')\n",
    "        self.dirInp = QLineEdit('/vol01/active_projects/anthony/ns650')\n",
    "        self.dirLayout.addWidget(dirLabel)\n",
    "        self.dirLayout.addWidget(self.dirInp)\n",
    "        \n",
    "        # create experiment box \n",
    "        self.filesLayout = QHBoxLayout()\n",
    "        self.filesLabel = QLabel('Space-delimited exp names: ')\n",
    "        self.filesInp = QLineEdit('aod ans')\n",
    "        self.filesLayout.addWidget(self.filesLabel)\n",
    "        self.filesLayout.addWidget(self.filesInp)\n",
    "        \n",
    "\n",
    "        # create target directory box \n",
    "        self.trgLayout = QHBoxLayout()\n",
    "        self.trgLabel = QLabel('Target Directory: ')\n",
    "        self.trgInp = QLineEdit('/vol01/active_projects/anthony/test_qt')\n",
    "        self.trgLayout.addWidget(self.trgLabel)\n",
    "        self.trgLayout.addWidget(self.trgInp)\n",
    "        \n",
    "         ############################################## TEXT EDITOR ##############################################\n",
    "        \n",
    "        # PROCESS IS A WIDGET NOT A LAYOUT \n",
    "        #self.process  = QTextEdit()\n",
    "        #self.process.moveCursor(QTextCursor.Start)\n",
    "        #self.process.ensureCursorVisible()\n",
    "        #self.process.setLineWrapColumnOrWidth(1000)\n",
    "        #self.process.setLineWrapMode(QTextEdit.FixedPixelWidth)\n",
    "        \n",
    "        ############################################## END EDITOR ##############################################\n",
    "        \n",
    "        #################################### ERP BUTTONS \n",
    "        # add create get h1's button\n",
    "        self.h1Button = QPushButton(\"Create h1 files\")\n",
    "        self.h1Button.clicked.connect(self.h1_handler)\n",
    "        self.h1Button.setToolTip(\"Instructions:\\nINPUTS => Directory\\nINPUTS => Experiments\\nINPUTS => Target Directory\")\n",
    "        \n",
    "        # add review data button \n",
    "        self.reviewButton = QPushButton(\"Review Data\")\n",
    "        self.reviewButton.clicked.connect(self.review_handler)\n",
    "        self.reviewButton.setToolTip(\"Instructions:\\nINPUTS => Directory\")\n",
    "\n",
    "        # add david's shell scripts \n",
    "        self.davidButton = QPushButton(\"Run ERP shell scripts\")\n",
    "        self.davidButton.clicked.connect(self.erp_shell_scripts)\n",
    "        self.davidButton.setToolTip(\"Instructions:\\nINPUTS => Directory\")\n",
    "        self.davidButton.resize(100,32)\n",
    "        \n",
    "        # add a clear button for editor\n",
    "        #clearButton = QPushButton('Clear all text')\n",
    "        #clearButton.clicked.connect(self.clear_function)\n",
    "        \n",
    "\n",
    "        # add dirLayout, files layout, start buttons to nav layout \n",
    "        self.erpLayout.addLayout(self.dirLayout)\n",
    "        self.erpLayout.addLayout(self.filesLayout)\n",
    "        self.erpLayout.addLayout(self.trgLayout)\n",
    "        \n",
    "        # add buttons \n",
    "        self.erpLayout.addWidget(self.h1Button)\n",
    "        self.erpLayout.addWidget(self.reviewButton)\n",
    "        self.erpLayout.addWidget(self.davidButton)\n",
    "        \n",
    "        # add nav layout to NAV TAB \n",
    "        self.h1Tab.setLayout(self.erpLayout)\n",
    "        \n",
    "        #################################### NEURO TAB ####################################\n",
    "        \n",
    "        # create vertical layout for neuropsych tab \n",
    "        self.neuroLayout = QVBoxLayout()\n",
    "    \n",
    "        # create directory box -- neuropsych \n",
    "        self.dirLayoutNeuro = QHBoxLayout()\n",
    "        dirLabelNeuro = QLabel('Directory: ')\n",
    "        self.dirInpNeuro = QLineEdit('/vol01/raw_data/staging/ucsd/oct_neuro')\n",
    "        self.dirLayoutNeuro.addWidget(dirLabelNeuro)\n",
    "        self.dirLayoutNeuro.addWidget(self.dirInpNeuro)\n",
    "        \n",
    "        \n",
    "        # create month box -- neuropsych \n",
    "        self.monthLayoutNeuro = QHBoxLayout()\n",
    "        monthLabelNeuro = QLabel('Enter month as integer: ')\n",
    "        self.monthInpNeuro = QLineEdit('10')\n",
    "        self.monthLayoutNeuro.addWidget(monthLabelNeuro)\n",
    "        self.monthLayoutNeuro.addWidget(self.monthInpNeuro)\n",
    "        \n",
    "        # create site box -- neuropsych \n",
    "        self.siteLayoutNeuro = QHBoxLayout()\n",
    "        siteLabelNeuro = QLabel('Enter site name: ')\n",
    "        self.siteInpNeuro = QLineEdit('site here')\n",
    "        self.siteLayoutNeuro.addWidget(siteLabelNeuro)\n",
    "        self.siteLayoutNeuro.addWidget(self.siteInpNeuro)\n",
    "        \n",
    "        # add directory, month, & site box to neuroLayout    \n",
    "        self.neuroLayout.addLayout(self.dirLayoutNeuro)\n",
    "        self.neuroLayout.addLayout(self.monthLayoutNeuro)\n",
    "        self.neuroLayout.addLayout(self.siteLayoutNeuro)\n",
    "        \n",
    "        # add neuroLayout to neuroTab\n",
    "        self.neuroTab.setLayout(self.neuroLayout)\n",
    "        \n",
    "        #################################### NEURO BUTTONS \n",
    "        # add check neuro raw data button \n",
    "        self.checkButtonNeuro = QPushButton(\"Check /raw_data/neuropsych/__sitename__\")\n",
    "        self.checkButtonNeuro.clicked.connect(self.check_neuro_handler)\n",
    "        self.checkButtonNeuro.setToolTip('INSTRUCTIONS:\\nINPUTS => Dirctory\\nINPUTS => Site Name')\n",
    "        \n",
    "        # add check for duplicates button \n",
    "        self.dupesButtonNeuro = QPushButton(\"Check for Duplicates\")\n",
    "        self.dupesButtonNeuro.clicked.connect(self.dupes_neuro_handler)\n",
    "        self.dupesButtonNeuro.setToolTip('INSTRUCTIONS:\\nINPUTS => Directory')\n",
    "        \n",
    "        # add neuro review button \n",
    "        self.reviewButtonNeuro = QPushButton(\"Run neuropsych check\")\n",
    "        self.reviewButtonNeuro.clicked.connect(self.review_neuro_handler)\n",
    "        self.reviewButtonNeuro.setToolTip('INSTRUCTIONS:\\nINPUTS => Directory\\nINPUTS => Month')\n",
    "    \n",
    "        # add move neuro files button \n",
    "        self.moveButtonNeuro = QPushButton(\"MOVE files to /raw_data/neuropsych/__sitename__\")\n",
    "        self.moveButtonNeuro.clicked.connect(self.move_neuro_handler)\n",
    "        \n",
    "        # add buttons to neuroLayout\n",
    "        self.neuroLayout.addWidget(self.checkButtonNeuro)\n",
    "        self.neuroLayout.addWidget(self.dupesButtonNeuro)\n",
    "        self.neuroLayout.addWidget(self.reviewButtonNeuro)\n",
    "        self.neuroLayout.addWidget(self.moveButtonNeuro)\n",
    "        \n",
    "        #################################################### END NEURO TAB ####################################################\n",
    "\n",
    "        #################################################### new std out tab \n",
    "        \n",
    "        self.processLayout = QVBoxLayout()\n",
    "        \n",
    "        self.process  = QTextEdit()\n",
    "        \n",
    "        \n",
    "        # add a clear button for editor\n",
    "        clearButton = QPushButton('Clear all text')\n",
    "        clearButton.clicked.connect(self.clear_function)\n",
    "        \n",
    "        self.processLayout.addWidget(self.process)\n",
    "        self.processLayout.addWidget(clearButton)\n",
    "        \n",
    "        self.redirectTab.setLayout(self.processLayout)\n",
    "        \n",
    "\n",
    "        \n",
    "        #################################################### end new std out tab \n",
    "         \n",
    "        \n",
    "        # Add tabs to tab widget \n",
    "        self.tabs.addTab(self.h1Tab,\"ERP\")\n",
    "        self.tabs.addTab(self.neuroTab,\"Neuropsych\")\n",
    "        self.tabs.addTab(self.redirectTab, \"Stdout & Stderr\")\n",
    "\n",
    "        \n",
    "        self.setCentralWidget(self.tabs)\n",
    "        self.show()\n",
    "        \n",
    "        \n",
    "        sys.stdout = EmittingStream(textWritten=self.redirect_output)\n",
    "        \n",
    "        \n",
    "    def redirect_output(self, text):\n",
    "\n",
    "        \"\"\"Append text to the QTextEdit.\"\"\"\n",
    "\n",
    "        # Maybe QTextEdit.append() works as well, but this is how I do it:\n",
    "\n",
    "        cursor = self.process.textCursor()\n",
    "        cursor.movePosition(QTextCursor.End)\n",
    "        cursor.insertText(text)\n",
    "        self.process.setTextCursor(cursor)\n",
    "        self.process.ensureCursorVisible()\n",
    "\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        sys.stdout = sys.__stdout__\n",
    "    ###################################################################\n",
    "        \n",
    "    def clear_function(self, signal):\n",
    "        self.process.clear()\n",
    "        \n",
    "    def test(self, signal):#### remove this function ######\n",
    "        \n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        self.erp_and_filesize_check(directoryInp)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    ############################################## ERP HANDLERS ##############################################\n",
    "    \n",
    "    def h1_handler(self, signal):\n",
    "        \"\"\" add a directories to exclude box?? \"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        directorytrg = self.trgInp.text().strip()\n",
    "        \n",
    "        \n",
    "        files = self.filesInp.text().strip()\n",
    "        files_lst = files.split(' ')\n",
    "        files_set = set(files_lst)\n",
    "        \n",
    "        dirs = [os.path.join(r,n) for r,d,f in os.walk(p1) for n in d]\n",
    "\n",
    "        count = 0\n",
    "        for i in dirs:\n",
    "            count+=1\n",
    "            print(\"\\n\\n{}\".format(count)), sd.get_h1s(i, files_set, del_ext=True, trg_dir=directorytrg)\n",
    "            \n",
    "            \n",
    "    def review_handler(self, signal):\n",
    "        directoryInp = self.dirInp.text().strip()\n",
    "        \n",
    "        dirs = [os.path.join(r,n) for r,d,f in os.walk(directoryInp) for n in d]\n",
    "        \n",
    "        count = 0\n",
    "        for i in dirs:\n",
    "            count+=1\n",
    "            print(\"\\n\\n{}\".format(count)), ep.run_all(i)\n",
    "        \n",
    "            \n",
    "            \n",
    "    def erp_shell_scripts(self, signal):\n",
    "        \n",
    "        buttonReply = QMessageBox.question(self, 'Confirmation Message', \"Are you sure?\", QMessageBox.Yes | QMessageBox.No, QMessageBox.No)\n",
    "        if buttonReply == QMessageBox.Yes:\n",
    "            directoryInp = self.dirInp.text().strip()\n",
    "            ep.iter_shell_check(directoryInp)\n",
    "        else:\n",
    "            print('No clicked.')\n",
    "        \n",
    "        \n",
    "    ############################################## NEURO HANDLERS ##############################################\n",
    "    \n",
    "    def check_neuro_handler(self, signal):\n",
    "        \"\"\"Check to see if new neuropsych data already exists in /raw_data/neuropsych/__sitename__\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        siteInp = self.siteInpNeuro.text().strip()\n",
    "        # my script\n",
    "        np_run_exists(directoryInp, siteInp)\n",
    "        \n",
    "        \n",
    "    def dupes_neuro_handler(self, signal):\n",
    "        \"\"\"Check for duplicate files in new neuropsych data from site\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        # my script \n",
    "        md5_check_walk(directoryInp)\n",
    "        \n",
    "        \n",
    "    def review_neuro_handler(self, signal):\n",
    "        \"\"\"Check for file naming/xml inconsistencies in new neuropsych data from site\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        monthInp = self.monthInpNeuro.text().strip()\n",
    "        # my script \n",
    "        neuro(directoryInp, int(monthInp))\n",
    "        \n",
    "\n",
    "    def move_neuro_handler(self, signal):\n",
    "        \"\"\"only after the above 3 functions are run, move new site data to /raw_data/neuropsych/__sitename__\"\"\"\n",
    "        \n",
    "        directoryInp = self.dirInpNeuro.text().strip()\n",
    "        siteInp = self.siteInpNeuro.text().strip()\n",
    "        # my script\n",
    "        move_neuro_files(directoryInp, siteInp)\n",
    "        \n",
    "    ############################################## END NEURO HANDLERS ##############################################\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app = QCoreApplication.instance() ### adding this if statement prevents kernel from crashing \n",
    "    if app is None:\n",
    "        app = QApplication(sys.argv)\n",
    "        print(app)\n",
    "    ex = App()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st neuro button  -- works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_run_exists(path_to_new_data, site):\n",
    "    '''given a path to new data and str(site) -- \n",
    "       tells if file already exists in directory'''\n",
    "    \n",
    "    np_basename = '/vol01/raw_data/neuropsych/'\n",
    "    \n",
    "    files = []\n",
    "    for r,d,f in os.walk(path_to_new_data):\n",
    "        for n in f:\n",
    "            files.append(n)\n",
    "            \n",
    "         \n",
    "    np_full_path = np_basename + site\n",
    "    \n",
    "    duplicate_files = []  \n",
    "    for r,d,f in os.walk(np_full_path):\n",
    "        for n in f:\n",
    "            if n in files:\n",
    "                path = os.path.join(r,n)\n",
    "                duplicate_files.append(path)\n",
    "    \n",
    "    if len(duplicate_files) == 0:\n",
    "        print('All files are unique')\n",
    "    else:\n",
    "        #pass\n",
    "        #print('im here')\n",
    "        #print('The following files already exist in', np_full_path, ' --->\\n\\n', [i for i in duplicate_files])\n",
    "        print('The following files already exist in {}...\\n'.format(np_full_path))\n",
    "        count = 0\n",
    "        for idx, i in enumerate(duplicate_files):\n",
    "            if idx % 5 == 0:\n",
    "                print('\\n{}'.format(i))\n",
    "            else:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd neuro button -- works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import os \n",
    "\n",
    "def md5(path):\n",
    "    '''generate md5 - -read file in binary mode'''\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        md5_return = hashlib.md5(data).hexdigest()\n",
    "        return md5_return\n",
    "    \n",
    "    \n",
    "    \n",
    "def md5_check_walk(dir_path):\n",
    "    '''given a dir path -- comapres md5 checksums across files and identifies duplicate files '''\n",
    "    md5_dict = defaultdict(list)\n",
    "    for r,d,f in os.walk(dir_path):\n",
    "        for n in f:\n",
    "            fp = os.path.join(r,n)\n",
    "            md5_dict[md5(fp)].append(fp)\n",
    "            \n",
    "    for k,v in md5_dict.items():\n",
    "        if len(v) > 1:  #multiple values for the same key\n",
    "            print(len(v), 'Duplicate files:', v,'\\n\\n\\n', 'with checksum', '\\n', k)\n",
    "        elif len(v) == 1:\n",
    "            print('No duplicates found {}'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd neuro button -- needs work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "def restart_script():\n",
    "    input('Please fix then press enter to restart program')\n",
    "    neuro(fp, 10)\n",
    "    \n",
    "def check_dict_len(dictionary, len_to_check):\n",
    "    '''used to check whether a file is empty or not '''\n",
    "    \n",
    "    for k,v in dictionary.items():\n",
    "        if len(v) < len_to_check:\n",
    "            print('Error:', k, 'is likely an empty file')\n",
    "    \n",
    "def neuro(fp, month_as_int):\n",
    "    \n",
    "    #1 -- check for unknown file types\n",
    "    for r,d,f in os.walk(fp):\n",
    "        for n in f:\n",
    "            if not n.endswith((\"xml\", \"txt\", \"_sum.txt\")):\n",
    "                path  = os.path.join(r,n)\n",
    "                print('\\n', 'Error: Unknown file types found --', path)\n",
    "                #sys.exit(1)\n",
    "\n",
    "\n",
    "    #2 -- check that all IDS have 8 numbers and all sum/txt files having CBST/TOLT in filename\n",
    "    for r,d, f in os.walk(fp):\n",
    "        for n in f:\n",
    "            if n.endswith((\"_sum.txt\", 'txt')):\n",
    "                split = n.split(\"_\")\n",
    "                if len(split[0]) != 8:\n",
    "                    print('Error: ID Incorrect Length -- ', split)\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    if split[1] == 'CBST':\n",
    "                        pass\n",
    "                    elif split[1] == 'TOLT':\n",
    "                        pass\n",
    "                    else:\n",
    "                        print('Error: Wrong experiment name -- ', split[0])\n",
    "                        #sys.exit(1)\n",
    "                        \n",
    "    # 3 -- check for empty files                     \n",
    "    xml_size_dict = {}\n",
    "    txt_size_dict = {}\n",
    "    for r,d,f in os.walk(fp):\n",
    "        for n in f:\n",
    "            if n.endswith('xml'):\n",
    "                with open(os.path.join(r,n), 'r') as file:\n",
    "                    for xml_line in file:\n",
    "                        path_xml= os.path.join(r,n)\n",
    "                        xml_size_dict.setdefault(path_xml, []).append(xml_line)\n",
    "            if n.endswith(('txt', '_sum.txt')):\n",
    "                with open(os.path.join(r,n), 'r') as file_txt:\n",
    "                    for txt_line in file_txt:\n",
    "                        path_txt= os.path.join(r,n)\n",
    "                        txt_size_dict.setdefault(path_txt, []).append(txt_line)\n",
    "\n",
    "    check_dict_len(xml_size_dict, 3)\n",
    "\n",
    "    check_dict_len(txt_size_dict, 3)\n",
    "\n",
    "    #4 -- create dictionary of each element in the filename \n",
    "    sum_txt_dict = {}\n",
    "    txt_dict = {}\n",
    "    xml_fname_dict = {}\n",
    "\n",
    "    for r,d,f in os.walk(fp):\n",
    "        ids_sumtxt = []\n",
    "        version_sumtxt = []\n",
    "        run_sumtxt = []\n",
    "        ext_sumtxt = []\n",
    "\n",
    "        ids_txt=[]\n",
    "        version_txt = []\n",
    "        run_txt = []\n",
    "        ext_txt = []\n",
    "\n",
    "\n",
    "        ids_xml = []\n",
    "        run_xml = []\n",
    "        ext_xml = []\n",
    "        for n in f:\n",
    "            if n.endswith('txt'):\n",
    "                if n.endswith('_sum.txt'):\n",
    "                    sumtxt_split = n.split('_')\n",
    "                    ids_sumtxt.append(sumtxt_split[0])\n",
    "                    version_sumtxt.append(sumtxt_split[2])\n",
    "                    run_sumtxt.append(sumtxt_split[3])\n",
    "                    ext_sumtxt.append(sumtxt_split[-1])\n",
    "                else:\n",
    "                    txt_split = re.split(r'[_.]', n)\n",
    "                    ids_txt.append(txt_split[0])\n",
    "                    version_txt.append(txt_split[2])\n",
    "                    run_txt.append(txt_split[3])\n",
    "                    ext_txt.append(txt_split[-1])\n",
    "            if n.endswith('xml'):\n",
    "                xml_split = n.split('_')\n",
    "                ids_xml.append(xml_split[0])\n",
    "                run_xml.append(xml_split[1])\n",
    "                ext_xml.append(xml_split[2])\n",
    "\n",
    "        tup_sumtxt = version_sumtxt, run_sumtxt, ext_sumtxt\n",
    "        tup_txt = version_txt, run_txt, ext_txt\n",
    "        tup_xml = run_xml, ext_xml\n",
    "\n",
    "        for i in ids_sumtxt:\n",
    "            sum_txt_dict[i] = tup_sumtxt\n",
    "\n",
    "        for j in ids_txt:\n",
    "            txt_dict[j] = tup_txt\n",
    "\n",
    "        for k in ids_xml:\n",
    "            xml_fname_dict[i] = tup_xml \n",
    "\n",
    "        ids_total = ids_sumtxt + ids_txt + ids_xml\n",
    "        ids_count_dict = Counter(ids_total)\n",
    "        for k,v in ids_count_dict.items():\n",
    "            if v != 5:\n",
    "                print('Error: There\\'s an ID missing from', k)\n",
    "                #sys.exit(1)\n",
    "\n",
    "    #####might need to add check to make sure sum_txt & txt dict keys are same length???\n",
    "\n",
    "    #5 -- check for version, run leter, and # of extensions for sum_txt files \n",
    "    for k,v in sum_txt_dict.items():\n",
    "        if len(list(set(v[0]))) != 1:\n",
    "            print('Error: Check version number for sum_txt file', k)\n",
    "        for i in v[0]:\n",
    "            if i != '1':\n",
    "                print('Error: Check version number for sum_txt file', k)\n",
    "        if len(list(set(v[1]))) != 1:\n",
    "            print('Error: Check run letter for sum_txt file', k)\n",
    "            sys.exit(1)\n",
    "        if len(v[2]) != 2:\n",
    "            print('Error: Missing sum_txt file for ID', k)\n",
    "\n",
    "\n",
    "    #6 -- check for version, run leter, and # of extensions for txt files \n",
    "    for k,v in txt_dict.items():\n",
    "        if len(list(set(v[0]))) != 1:\n",
    "            print('Error: Check version number for txt file', k)\n",
    "        for i in v[0]:\n",
    "            if i != '1':\n",
    "                print('Error: Check version number for txt file', k)\n",
    "        if len(list(set(v[1]))) != 1:\n",
    "            print('Error: Check run letter for txt file', k)\n",
    "            sys.exit(1)\n",
    "        if len(v[2]) != 2:\n",
    "            print('Error: Missing txt file for ID txt file', k)\n",
    "\n",
    "\n",
    "    #7 -- check to see if version and run letter are identical across txt & sum_txt files\n",
    "    for k,v in sum_txt_dict.items():\n",
    "        if k in txt_dict.keys():\n",
    "            if not v[0] == txt_dict[k][0]:\n",
    "                print('Error: Version number between sum.txt & txt files don\\'t match for', k)\n",
    "            if not v[1]  == txt_dict[k][1]:\n",
    "                print('Error: Run letter between sum.txt & txt files don\\'t match for', k)\n",
    "                sys.exit(1)\n",
    "\n",
    "    #8 -- check for things inside xml file            \n",
    "    xml = [os.path.join(root,name) for root,dirs,files in os.walk(fp) for name in files if name.endswith(\".xml\")]\n",
    "\n",
    "    within_xml_id = []\n",
    "    within_xml_run = []\n",
    "    xml_motiv = []\n",
    "\n",
    "\n",
    "    xml_dict_new = {}\n",
    "    for i in xml:\n",
    "        lst_xml_id = []\n",
    "        dob_lst = []\n",
    "        testdate_lst = []\n",
    "        gender_lst = []\n",
    "        hand_lst = []\n",
    "        with open(i) as f:\n",
    "            for line in f:\n",
    "                if line.startswith('  <Sub'):\n",
    "                    lst_xml_id.extend(re.findall(r'<SubjectID>(.*?)</SubjectID>', line))\n",
    "                    within_xml_id.extend(re.findall(r'<SubjectID>(.*?)</SubjectID>', line))\n",
    "                if line.startswith('  <Sess'):\n",
    "                    within_xml_run.extend(re.findall(r'<SessionCode>(.*?)</SessionCode>', line))\n",
    "                if line.startswith('  <Motivation>'):\n",
    "                    xml_motiv.extend(re.findall(r'<Motivation>(.*?)</Motivation>', line))\n",
    "                if line.startswith('  <DOB>'):\n",
    "                    dob_lst.extend(re.findall(r'<DOB>(.*?)</DOB>', line))\n",
    "                if line.startswith('  <TestDate>'):\n",
    "                    testdate_lst.extend(re.findall(r'<TestDate>(.*?)</TestDate>', line))\n",
    "                if line.startswith('  <Gender>'):\n",
    "                    gender_lst.extend(re.findall(r'<Gender>(.*?)</Gender>', line))\n",
    "                if line.startswith('  <Hand>'):\n",
    "                    hand_lst.extend(re.findall(r'<Hand>(.*?)</Hand>', line))\n",
    "                    \n",
    "                xml_tuples = dob_lst, testdate_lst, gender_lst, hand_lst\n",
    "                for i in lst_xml_id:\n",
    "                    xml_dict_new[i] = xml_tuples\n",
    "                    \n",
    "    now = datetime.datetime.now().year\n",
    "    \n",
    "\n",
    "    #9 -- xml check for accurate DOB, testdate, & that gender and version start with uppercase letter\n",
    "    for k,v in xml_dict_new.items():\n",
    "        for i in v[0]:\n",
    "            date_split = i.split('/')\n",
    "            year = int(date_split[-1])\n",
    "            if year > 2015:\n",
    "                print('Error: Check DOB in xml file for', k)\n",
    "        for j in v[1]:\n",
    "            testdate_split = j.split('/')\n",
    "            year_test = int(testdate_split[-1])\n",
    "            if year_test != now:\n",
    "                print('Error: Check test date in xml file for', k)\n",
    "            if int(month_as_int) != int(testdate_split[0]):\n",
    "                print('Error: Month of test date in xml file incorrect for', k )\n",
    "        for l in v[2]:\n",
    "            if not l[0].isupper(): #maybe str.istitle() would be better?\n",
    "                print('Error: Make gender uppercase in xml file for', k)\n",
    "        for m in v[3]:\n",
    "            if not m[0].isupper():\n",
    "                print('Error: Make handedness uppercase in xml file for', k)\n",
    "\n",
    "    inside_xml = dict(zip(within_xml_id, within_xml_run))\n",
    "\n",
    "    #10 -- xml check for length of sub IDs \n",
    "    xml_ids = [('Error: Check inside xml file for sub ID', i) for i in within_xml_id if len(i) != 8]\n",
    "    if len(xml_ids) != 0:\n",
    "        print(xml_ids)\n",
    "\n",
    "    #11 -- 12 will only work if 2 xml dicts have the same keys \n",
    "    missing_xml_keys = set(xml_fname_dict.keys() ^ inside_xml.keys())\n",
    "    \n",
    "    if len(list(missing_xml_keys)) > 0:\n",
    "        print('Error: Check', missing_xml_keys, 'folder for missing xml files/'\n",
    "              'incorrect sub ID within xml file' )\n",
    "        sys.exit(1)\n",
    "\n",
    "    #12 -- check to see if run letter within xml matches xml filename    \n",
    "    for k,v in xml_fname_dict.items():\n",
    "        for l in v[0]:\n",
    "            if k in inside_xml.keys():\n",
    "                if l not in inside_xml[k]:\n",
    "                    print('Error: Check', k, 'folder for mismatch between xml run letter and xml filename run letter')\n",
    "                    sys.exit(1)\n",
    "\n",
    "    #13 -- since we know txt & sum_txt run letters are identical & that inside and xml fname run letters are identical...\n",
    "    #13... check run letters against xml & sum_txt files \n",
    "    for k,v in txt_dict.items():\n",
    "        run_letter = v[1][0][0]\n",
    "        if k in inside_xml.keys():\n",
    "            if run_letter not in inside_xml.values():\n",
    "                print('Error: Check', k, 'folder for mismatch between xml run letter and xml filename run letter')\n",
    "                sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review site data  -- 1st & 3rd buttons -- both work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "class erp_data:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # avg + ps exp names are the same\n",
    "        self.avg_and_ps_exps = ['vp3', 'cpt', 'ern', 'ant', 'aod', 'anr', 'stp', 'gng']\n",
    "        # number of files associated with avg extension \n",
    "        self.avg_exp_nums = [3,6,4,4,2,2,2,2]\n",
    "        # cnt exp names\n",
    "        self.cnt_exp_list = ['eeo', 'eec', 'vp3', 'cpt', 'ern', 'ant', 'aod', 'ans', 'stp', 'gng']\n",
    "        # versions associated with erp \n",
    "        self.version_list = ['4', '4', '6', '4', '9', '6', '7', '5', '3', '3']\n",
    "        # dat exp names \n",
    "        self.dat_exps = ['vp3', 'cpt', 'ern', 'ant', 'aod', 'ans', 'stp', 'gng']\n",
    "        # only 1 exp for dat/cnt/ps\n",
    "        self.exp_nums_single = [1] * len(self.cnt_exp_list)\n",
    "\n",
    "\n",
    "    def check_erp_version(self, path, exp_name, version_num): \n",
    "        \"\"\"\n",
    "        returns whether ERP experiment version is correct \n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.exp_name = exp_name\n",
    "        self.version_num = version_num\n",
    "\n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                split = n.split('_')\n",
    "                if n.startswith((exp_name)):\n",
    "                    if split[1] != version_num:\n",
    "                        return 'Check version for {}'.format(n)\n",
    "\n",
    "\n",
    "    def iter_check_version(self, path, cnt_exp_list, version_list):\n",
    "        \"\"\"\n",
    "        iterator version of check_erp_version()\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "        for exp, version in zip(self.cnt_exp_list, self.version_list):\n",
    "            out = self.check_erp_version(path, exp, version)\n",
    "            if out is None:\n",
    "                pass\n",
    "            else:\n",
    "                return str(out)\n",
    "\n",
    "\n",
    "    def parse_site_data(self, path):\n",
    "        \"\"\"\n",
    "        returns a nested dictionary of common/uncommon file extensions by experiment for a sub\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        key = path.split('/')[-1]\n",
    "\n",
    "        nested_dict = {}\n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                if n.endswith('_32.cnt'):\n",
    "                    cnts = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('cnt', []).append(cnts[0])\n",
    "                if n.endswith('dat'):\n",
    "                    dats = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('dat', []).append(dats[0])\n",
    "                if n.endswith('_avg.ps'):\n",
    "                    pss = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('ps', []).append(pss[0])\n",
    "                if n.endswith('.avg'):\n",
    "                    avgs = re.split(r'[_.]', n)\n",
    "                    nested_dict.setdefault(key, {}).setdefault('avg', []).append(avgs[0])\n",
    "                if n.endswith('_orig.cnt'):\n",
    "                    origs = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('orig_cnt', []).append(origs[0])\n",
    "                if n.endswith('_32_original.cnt'):\n",
    "                    bad_orig = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('bad_orig', []).append(bad_orig[0])\n",
    "                if n.endswith('_rr.cnt'):\n",
    "                    reruns = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('rerun', []).append(reruns[0])\n",
    "                if n.endswith('_cnt.h1'):\n",
    "                    cnt_h1 = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('cnt_h1', []).append(cnt_h1[0])\n",
    "                if n.endswith('_avg.h1'):\n",
    "                    avg_h1 = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('h1', []).append(avg_h1[0])\n",
    "                if n.endswith('_avg.h1.ps'):\n",
    "                    h1_ps = n.split('_')\n",
    "                    nested_dict.setdefault(key, {}).setdefault('h1_ps', []).append(h1_ps[0])\n",
    "\n",
    "        return nested_dict\n",
    "\n",
    "\n",
    "    def remove_wild_files(self, path):\n",
    "        \"\"\"\n",
    "        prompts user to delete file extensions that don't belong in ns folders\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        wild_files = []\n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                if n.endswith(('_32.cnt', '_orig.cnt', 'avg', 'avg.ps', 'dat', 'txt', 'sub')):\n",
    "                    pass\n",
    "                else:\n",
    "                    fp = os.path.join(r,n)\n",
    "                    wild_files.append(fp)\n",
    "        count = 0\n",
    "        for wild in wild_files:\n",
    "            count+=1\n",
    "            print(\"\\n{} || {}\".format(count, wild))\n",
    "            ans= input('\\nDo you want to delete this file?\\n> ')\n",
    "            if ans in ['y', 'Y', 'Yes', 'yes']:\n",
    "                #os.remove(wild)\n",
    "                print('deleting')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "    def get_ext_count(self, path, nested_dict, ext_type, exp_name, number_files):\n",
    "        \"\"\"\n",
    "        checks nested dictionary for number of extensions associated with each experiment\n",
    "        e.g. checks that there's 6 CPT avg files or 1 EEC cnt file...\n",
    "        \"\"\"\n",
    "\n",
    "        self.path = path\n",
    "        self.nested_dict = nested_dict\n",
    "        self.ext_type = ext_type\n",
    "        self.exp_name = exp_name\n",
    "        self.number_files = number_files\n",
    "\n",
    "        output = []\n",
    "        for k,v in nested_dict.items():\n",
    "            for k1, v1 in v.items():\n",
    "                if ext_type == k1:\n",
    "                    num_files = v1.count(exp_name)\n",
    "                    if num_files != number_files:\n",
    "                        return 'Incorrect number of {} {} files in {}'.format(exp_name, ext_type, path)\n",
    "\n",
    "\n",
    "    # get_ext_count()\n",
    "    def iter_exps(self, path, nested_dict, exp_list, exp_list_avgs, ext_type):\n",
    "        \"\"\"\n",
    "        iterator version of iter_exps()\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.exp_list = exp_list\n",
    "        self.exp_list_avgs = exp_list_avgs\n",
    "        self.ext_type = ext_type\n",
    "\n",
    "        for exp, avg_nums in zip(exp_list, exp_list_avgs):\n",
    "            out = self.get_ext_count(path, nested_dict, ext_type, exp, avg_nums)\n",
    "            if out is None:\n",
    "                pass\n",
    "            else:\n",
    "                return str(out)\n",
    "\n",
    "\n",
    "    def check_id_and_run(self, path):\n",
    "        \"\"\"\n",
    "        checks to see if important file extensions have same sub ID & run letter\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        folder = path.split('/')[-1]\n",
    "\n",
    "        sub_id_list = []\n",
    "        run_letter_list = []\n",
    "\n",
    "        for file in glob(os.path.join(path, '*.*')):\n",
    "            if file.endswith(('_32.cnt', '_orig.cnt', '_avg.ps', '.avg', 'dat')):\n",
    "                fname = os.path.basename(file)\n",
    "                if not fname.endswith(('avg', 'dat')):\n",
    "                    sub_id = fname.split('_')[3]\n",
    "                    sub_id_list.append(sub_id)\n",
    "                else:\n",
    "                    avg_dat_ids = re.split(r'[_.A-Z]', fname)\n",
    "                    sub_id_list.append(avg_dat_ids[3])\n",
    "\n",
    "                # append run letters \n",
    "                run_letter_list.append(fname.split('_')[2][0])\n",
    "\n",
    "\n",
    "        unique_ids = list(set(sub_id_list))\n",
    "        unique_run_letters = list(set(run_letter_list))\n",
    "\n",
    "        if  len(unique_ids) > 1:\n",
    "            return str(\"Folder {} has more than one sub ID => {}\".format(folder, unique_ids))\n",
    "\n",
    "        if len(unique_run_letters) > 1:\n",
    "            return str(\"Folder {} has more than one run letter => {}\".format(folder, unique_run_letters))\n",
    "\n",
    "\n",
    "    def print_erp_version(self, path, cnt_exp_list, version_list):\n",
    "        \"\"\"\n",
    "        check erp version \n",
    "        \"\"\"\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "        print('\\n\\nERP VERSION CHECK:')\n",
    "\n",
    "        iter_check = self.iter_check_version(path, self.cnt_exp_list, self.version_list)\n",
    "        if  iter_check is None:\n",
    "            print('All versions check out!')\n",
    "        else:\n",
    "            print(iter_check)\n",
    "\n",
    "\n",
    "    def print_file_counts(self, nested_data_dict):\n",
    "        \"\"\"\n",
    "        returns counts of file extensions\n",
    "        \"\"\"\n",
    "\n",
    "        self.nested_data_dict = nested_data_dict\n",
    "\n",
    "        print('\\n\\nFILES COUNT:')\n",
    "        for k,v in nested_data_dict.items():\n",
    "            for k1,v1 in v.items():\n",
    "                print(\"There are {} {} files\".format(len(v1), k1.upper()))\n",
    "\n",
    "\n",
    "    def print_missing_exps(self, path, nested_data_dict):\n",
    "        \"\"\"\n",
    "        returns file type that's missing, if any \n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.nested_data_dict = nested_data_dict\n",
    "\n",
    "        print('\\n\\nMissing Experiments:')\n",
    "\n",
    "\n",
    "        avg_counts = self.iter_exps(path, nested_data_dict, self.avg_and_ps_exps, self.avg_exp_nums, 'avg')\n",
    "\n",
    "        if avg_counts is None:\n",
    "            print('All avg files found!')\n",
    "        else:\n",
    "            print(avg_counts)\n",
    "\n",
    "\n",
    "        cnt_counts = self.iter_exps(path, nested_data_dict, self.cnt_exp_list, self.exp_nums_single, 'cnt')\n",
    "        if cnt_counts is None:\n",
    "            print('All cnt files found!')\n",
    "        else:\n",
    "            print(cnt_counts)\n",
    "\n",
    "\n",
    "        ps_counts = self.iter_exps(path, nested_data_dict, self.avg_and_ps_exps, self.exp_nums_single, 'ps')\n",
    "        if ps_counts is None:\n",
    "            print('All ps files found!')\n",
    "        else:\n",
    "            print(ps_counts)\n",
    "\n",
    "\n",
    "        dat_counts = self.iter_exps(path, nested_data_dict, self.dat_exps, self.exp_nums_single, 'dat')\n",
    "        if dat_counts is None:\n",
    "            print('All dat files found!')\n",
    "        else:\n",
    "            print(dat_counts)\n",
    "\n",
    "\n",
    "    def print_wild_files(self, path):\n",
    "        \"\"\"\n",
    "        returns files that don't belong\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        print(\"\\n\\nFILES THAT DON'T BELONG IN NS FOLDERS:\")\n",
    "        self.remove_wild_files(path)\n",
    "\n",
    "\n",
    "    def print_id_and_letter(self, path):\n",
    "        \"\"\"\n",
    "        returns ID & run letter, should both be unique\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        print('\\n\\nCHECK SUBJECT ID & RUN LETTER:')\n",
    "\n",
    "        if self.check_id_and_run(path) is None:\n",
    "            print('All IDs & run letters check out!')\n",
    "        else:\n",
    "            print(self.check_id_and_run(path))\n",
    "\n",
    "\n",
    "    def run_all(self, path):\n",
    "        \"\"\"\n",
    "        2nd to last step \n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        nested_data_dict = self.parse_site_data(path)\n",
    "\n",
    "        self.print_erp_version(path, self.cnt_exp_list, self.version_list)\n",
    "        self.print_file_counts(nested_data_dict)\n",
    "        self.print_missing_exps(path, nested_data_dict)\n",
    "        self.print_id_and_letter(path)\n",
    "\n",
    "\n",
    "    def execute_all(self, path):\n",
    "        \"\"\"\n",
    "        last step\n",
    "        \"\"\"\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "        test = [os.path.join(r,n) for r,d,f in os.walk(path) for n in d]\n",
    "\n",
    "        if len(test) == 0:\n",
    "            self.run_all(path)\n",
    "        else:\n",
    "            fps = [os.path.join(r,n) for r,d,f in os.walk(path) for n in d]\n",
    "            count=0\n",
    "            for i in fps:\n",
    "                print(\"\\n\\n{} || {}\".format(count, i))\n",
    "                self.run_all(i)\n",
    "                count+=1\n",
    "                \n",
    "\n",
    "    # anything below here doesn't get executed in execute_all()\n",
    "    def shell_filesize_check(self, path):\n",
    "        \"\"\"\n",
    "        return stdout & stderr from David's ERP shell scripts \n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        erp_check = subprocess.Popen('ERP-raw-data_check.sh {}'.format(path), shell=True, \n",
    "                                      stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=path)\n",
    "        result_erp = erp_check.communicate()[0]\n",
    "        print(\"ERP CHECK: {} {}\".format(path, result_erp.decode('ascii')))\n",
    "        \n",
    "        \n",
    "        size_check = subprocess.Popen('DVD-file-size_check.sh {}'.format(path), shell=True, \n",
    "                                      stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=path)\n",
    "        result_size = size_check.communicate()[0]\n",
    "        print('FILE SIZE CHECK: {} {}\\n\\n'.format(path, result_size.decode('ascii')))\n",
    "\n",
    "\n",
    "    def iter_shell_check(self, path):\n",
    "        \"\"\"\n",
    "        iterate over directories checking with shell scripts \n",
    "        \"\"\"\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "        test = [os.path.join(r,n) for r,d,f in os.walk(path) for n in d]\n",
    "\n",
    "        if len(test) == 0:\n",
    "            self.shell_filesize_check(path)\n",
    "        else:\n",
    "            fps = [os.path.join(r,n) for r,d,f in os.walk(path) for n in d]\n",
    "            count=0\n",
    "            for i in fps:\n",
    "                print(\"\\n{} || {}\".format(count, i))\n",
    "                self.shell_filesize_check(i)\n",
    "                count+=1\n",
    "\n",
    "\n",
    "ep = erp_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create h1 button -- 2nd button -- works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "class site_data:\n",
    "    #get_h1s()\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.ant_set = {'ant'}\n",
    "        self.ans_set = {'ans'}\n",
    "        self.other_exps = {'vp3', 'cpt', 'ern', 'aod', 'stp', 'gng'}\n",
    "                \n",
    "    def check_cnt_copy(self, path, exp_tuple):\n",
    "        \"\"\"\n",
    "        checks to see if files you want to h1 are actually in the directory to begin with\n",
    "        \"\"\"\n",
    "\n",
    "        self.path = path\n",
    "        self.exp_tuple = exp_tuple\n",
    "\n",
    "        cnt_dict = {}\n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                if n.startswith((exp_tuple)) and n.endswith('_32.cnt'):\n",
    "                    split = n.split('_')\n",
    "                    cnt_dict.setdefault(split[3], []).append(split[0])\n",
    "\n",
    "\n",
    "        for k,v in cnt_dict.items():\n",
    "            if len(v) is not len(exp_tuple):\n",
    "                missing_exp = '.'.join(str(s) for s in (set(v) ^ set(list(exp_tuple))))\n",
    "                print('\\n\\nLOOK HERE!!!{} cnt file missing from {}\\n\\n'.format(missing_exp.upper(), path))\n",
    "                \n",
    "    #get_h1s()                \n",
    "    def rename_cnts(self, path, skip=False):\n",
    "        \"\"\"\n",
    "        rename file ending with _rr.cnt if it doesn't already exist\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.skip = skip\n",
    "\n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                if n.endswith('_rr.cnt'):\n",
    "                    new_name = os.path.join(r, n[:-7] + '.cnt')\n",
    "                    if not os.path.exists(new_name):\n",
    "                        path = os.path.join(r,n)\n",
    "                        os.rename(os.path.join(r,n), new_name)\n",
    "                        print(\"Renaming {}\".format(n))\n",
    "                    else:\n",
    "                        print(\"{} already exists!!\".format(new_name))\n",
    "        \n",
    "        if skip:\n",
    "            for r,d,f in os.walk(path):\n",
    "                for n in f:\n",
    "                    if n.endswith('_rr.cnt'):\n",
    "                        print(\"Re-run found for {} -- create manually\".format(n))\n",
    "    #get_h1s()                    \n",
    "    def create_cnth1(self, path):\n",
    "        \"\"\"\n",
    "        create cnt.h1 files from shell script\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        \n",
    "        print('\\n\\n>>> MAKING CNT.H1 FILES <<<\\n') \n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                if n.startswith(self.cnth1_tups) and n.endswith('_32.cnt'):\n",
    "                    path = os.path.join(r,n)\n",
    "                    p = subprocess.Popen(\"create_cnthdf1_from_cntneuroX.sh {}\".format(path),shell=True, \n",
    "                                          stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(path))\n",
    "                    result = p.communicate()[1]\n",
    "                    print(result.decode('ascii'))\n",
    "\n",
    "    #get_h1s()\n",
    "    def create_avgh1(self, path):\n",
    "        \"\"\"\n",
    "        create avg.h1 files from shell script\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "\n",
    "        print('\\n\\n>>> Making AVG.H1 FILES <<<\\n') \n",
    "        for r,d,f in os.walk(path):\n",
    "            for n in f:\n",
    "                if n.startswith(self.ant_tup) and n.endswith('cnt.h1'):\n",
    "                    ant_path = os.path.join(r,n)\n",
    "                    p_ant = subprocess.Popen('create_avghdf1_from_cnthdf1X -lpfilter 8 -hpfilter 0.03 -thresh 75 -baseline_times -125 0 {}'.format(ant_path), \n",
    "                                             shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(ant_path))\n",
    "                    result_ant = p_ant.communicate()[1]\n",
    "                    print(result_ant.decode('ascii'))\n",
    "                if n.startswith(self.ans_tup) and n.endswith('cnt.h1'):\n",
    "                    ans_path = os.path.join(r,n)\n",
    "                    p_ans = subprocess.Popen('create_avghdf1_from_cnthdf1X -lpfilter 16 -hpfilter 0.03 -thresh 100 -baseline_times -125 0 {}'.format(ans_path), \n",
    "                                            shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(ans_path))\n",
    "                    result_ans = p_ans.communicate()[1]\n",
    "                    print(result_ans.decode('ascii'))\n",
    "                if n.startswith((self.others_tup)) and n.endswith('cnt.h1'):\n",
    "                    path=os.path.join(r,n)\n",
    "                    p_others = subprocess.Popen('create_avghdf1_from_cnthdf1X -lpfilter 16 -hpfilter 0.03 -thresh 75 -baseline_times -125 0 {}'.format(path), \n",
    "                                                shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=os.path.dirname(path))\n",
    "                    result_others = p_others.communicate()[1]\n",
    "                    print(result_others.decode('ascii'))\n",
    "    #get_h1s()\n",
    "    def create_avgps(self, path):\n",
    "        \"\"\"\n",
    "        create avg.h1.ps files from shell script\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = path\n",
    "\n",
    "        print('\\n\\n>>> Making AVG.PS FILES <<<\\n') \n",
    "        for path, subdirs, files in os.walk(path):\n",
    "            for name in files:\n",
    "                if name.endswith(\"avg.h1\"):\n",
    "                    ps_paths = os.path.join(path, name)\n",
    "                    subprocess.Popen(\"plot_hdf1_data.sh {}\".format(name), shell=True, cwd=os.path.dirname(ps_paths))\n",
    "                    print(\"creating ps files.. \" + name)\n",
    "                    \n",
    "        #get_h1s()                \n",
    "    def delete_bad_files(self, path, exts_to_keep=None, to_be_deleted_set=None):\n",
    "        ''' returns any extension not in exts_to_keep & prompts user to delete '''\n",
    "    \n",
    "        self.path = path\n",
    "        self.exts_to_keep = exts_to_keep\n",
    "        self.to_be_deleted_set = to_be_deleted_set\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"\\n\\n>>> REMOVING FILES <<<\\n\") \n",
    "        if exts_to_keep:\n",
    "\n",
    "            for r,d,f in os.walk(path):\n",
    "                for n in f:\n",
    "                    if n.endswith(('_cnt.h1')):\n",
    "                        os.remove(os.path.join(r,n))\n",
    "                        print('Removing {}'.format(n))\n",
    "\n",
    "        if to_be_deleted_set:\n",
    "            \n",
    "            for r,d,f in os.walk(path):\n",
    "                for n in f:\n",
    "                    if n.endswith(('_32.cnt', '_cnt.h1')):\n",
    "                        os.remove(os.path.join(r,n))\n",
    "                        print('Removing {}'.format(n))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def get_h1s(self, path, set_of_exps, del_ext=None, ps=None, trg_dir=None):\n",
    "        '''combines all these commands together'''\n",
    "        \n",
    "        self.path = path\n",
    "        self.set_of_exps = set_of_exps\n",
    "        self.ps = ps\n",
    "        self.trg_dir = trg_dir\n",
    "        \n",
    "        #use in create_cnth1()\n",
    "        self.cnth1_tups = tuple(set_of_exps)\n",
    "        \n",
    "        if_ant = self.ant_set & set_of_exps\n",
    "        if_ans = self.ans_set & set_of_exps\n",
    "        all_others = self.other_exps & set_of_exps\n",
    "        \n",
    "        #used in create_avgh1()\n",
    "        self.ant_tup = tuple(if_ant)\n",
    "        self.ans_tup = tuple(if_ans)\n",
    "        self.others_tup = tuple(all_others)\n",
    "\n",
    "        #if being used for peak picking, create new directories and move all cnt files to the correct folder...and so on\n",
    "        if trg_dir:\n",
    "            #create new directories\n",
    "            exps_list = list(set_of_exps)\n",
    "            for exp in exps_list:\n",
    "                new_dirs = os.path.join(trg_dir, exp)\n",
    "                if not os.path.exists(new_dirs):\n",
    "                    os.makedirs(new_dirs)\n",
    "                    print(\">>> Creating {} <<<\".format(new_dirs))\n",
    "                else:\n",
    "                    #print(\"{} already exist\".format(new_dirs))\n",
    "                    pass\n",
    "            #copy cnt files to newly created directories       \n",
    "            count = 0\n",
    "            print('\\n>>> COPYING CNT FILES <<<\\n')\n",
    "            for r,d,f in os.walk(path):\n",
    "                for n in f:\n",
    "                    if n.startswith(self.cnth1_tups) and n.endswith('_32.cnt'):\n",
    "                        count+=1\n",
    "                        print('Copying {}'.format(n))\n",
    "                        shutil.copy(os.path.join(r,n), os.path.join(trg_dir, n[:3]))\n",
    "            print('\\nCopied {} of {} files'.format(count, len(self.cnth1_tups)))\n",
    "\n",
    "            self.rename_cnts(path)\n",
    "            self.check_cnt_copy(trg_dir, self.cnth1_tups)\n",
    "            self.create_cnth1(trg_dir)\n",
    "            self.create_avgh1(trg_dir)\n",
    "            if ps:\n",
    "                self.create_avgps(trg_dir)\n",
    "            if del_ext:\n",
    "                self.delete_bad_files(trg_dir, to_be_deleted_set=True)\n",
    "            return True\n",
    "        \n",
    "        #if you want to create avg.h1s IN directory copying files...\n",
    "        self.rename_cnts(path, skip=True)\n",
    "        self.create_cnth1(path)\n",
    "        self.create_avgh1(path)\n",
    "        if ps:\n",
    "            self.create_avgps(path)\n",
    "        if del_ext:\n",
    "            self.delete_bad_files(path, exts_to_keep=True)\n",
    "\n",
    "\n",
    "sd = site_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dbI]",
   "language": "python",
   "name": "conda-env-dbI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
